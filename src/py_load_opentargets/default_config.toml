# Default configuration for the Open Targets data loader.
# Users can override these settings by creating their own config.toml.

[execution]
# The number of parallel threads to use for downloading and processing datasets.
# A value of 1 means sequential processing.
max_workers = 4

[database]
# The name of the database backend to use.
# This must match an entry point in the 'py_load_opentargets.backends' group.
backend = "postgres"
# Separator to use when creating column names for flattened struct fields.
# e.g., 'ancestors' struct with 'id' field becomes 'ancestors_id'.
flatten_separator = "_"

[source]
# fsspec-compatible URI for discovering available Open Targets versions.
# This points to the FTP server where version directories like '22.04' are listed.
version_discovery_uri = "ftp://ftp.ebi.ac.uk/pub/databases/opentargets/platform/"

# fsspec-compatible URI template for downloading the checksum manifest.
# This points to the root of a specific version on the FTP server.
checksum_uri_template = "ftp://ftp.ebi.ac.uk/pub/databases/opentargets/platform/{version}/"

# fsspec-compatible URI template for downloading dataset parquet files.
# This uses GCS for high-speed downloads.
# Placeholders {version} and {dataset_name} will be filled in by the application.
data_download_uri_template = "gcs://open-targets/platform/{version}/output/etl/parquet/{dataset_name}/"


# --- S3 Data Source Example ---
# To use a private S3 bucket as the data source, comment out the default URIs
# above and uncomment the lines below.
#
# You must also install the S3 dependency: pip install .[s3]
#
# Your environment must be configured with AWS credentials (e.g., via environment
# variables AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY).
#
# version_discovery_uri = "s3://your-opentargets-bucket/platform/"
# checksum_uri_template = "s3://your-opentargets-bucket/platform/{version}/"
# data_download_uri_template = "s3://your-opentargets-bucket/platform/{version}/output/etl/parquet/{dataset_name}/"


# Definitions for each dataset to be loaded.
# Each dataset needs a 'primary_key' list for the merge (UPSERT) operation.
# An optional 'final_table_name' can be provided to override the default,
# which is the dataset name itself (with '-' replaced by '_').
[datasets]

[datasets.targets]
primary_key = ["id"]
# The 'schema_overrides' table provides fine-grained control over how columns
# are processed and mapped to the database schema.
[datasets.targets.schema_overrides]
  # For the 'id' column, rename it to 'target_id' in the final table.
  id = { rename = "target_id" }
  # The 'tep' column is a struct. 'action = "flatten"' will expand its
  # sub-fields (e.g., 'uri', 'name') into new columns ('tep_uri', 'tep_name').
  tep = { action = "flatten" }
  # 'genomicLocation' is also a struct to be flattened.
  genomicLocation = { action = "flatten" }
  # 'obsoleteTerms' is an array of structs. 'action = "json"' will serialize
  # the entire array into a single JSONB column for flexible querying.
  obsoleteTerms = { action = "json" }

[datasets.diseases]
primary_key = ["id"]

[datasets.drugs]
# The 'id' column for drugs is the ChEMBL ID.
primary_key = ["id"]

[datasets.evidence]
# Each evidence string has a unique ID.
primary_key = ["id"]

[datasets.molecule]
primary_key = ["id"]
final_table_name = "molecule"

[datasets.mousePhenotypes]
primary_key = ["targetId", "diseaseId"]
final_table_name = "mouse_phenotypes"

[datasets.associationByDatasourceDirect]
primary_key = ["targetId", "diseaseId", "datasourceId"]
final_table_name = "association_direct_by_datasource"

[datasets.associationByDatasourceIndirect]
primary_key = ["targetId", "diseaseId", "datasourceId"]
final_table_name = "association_indirect_by_datasource"

[datasets.associationByOverallDirect]
primary_key = ["targetId", "diseaseId"]
final_table_name = "association_direct_overall"

[datasets.associationByOverallIndirect]
primary_key = ["targetId", "diseaseId"]
final_table_name = "association_indirect_overall"
